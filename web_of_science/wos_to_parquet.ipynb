{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: converting XML files to Parquet format with Web of Science Data\n",
    "- These data files come from the University of Michigan's copy of the [Web of Science](https://www.webofknowledge.com/). Rather than using the API, our library has purchased access to a dump of the data.\n",
    "- Remember, the first step is always to convert out of a native format like XML or json and into something optimized for performance like parquet. \n",
    "- When launching PySpark to read XML, it is important to include the command line argument `--packages com.databricks:spark-xml_2.11:0.5.0` when specifying other settings, like number of executors.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "#import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "sqlC = SQLContext(sc)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = sqlC.read.format(\"com.databricks.spark.xml\"\n",
    "#                     ).option(\"rowTag\", \"REC\"\n",
    "#                             ).load(\"/user/jwlock/WoS/WR_1947_20170220224016_CORE_0001.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.write.option(\"maxRecordsPerFile\", \n",
    "#                10000\n",
    "#               ).parquet('test.parquet', \n",
    "#                         mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting all files in a directory\n",
    "- Sampling ratio here is the number of records spark peaks at to determing the format of records before processing them all. Smaller sampling ratios mean faster runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cites = sqlC.read.format(\"com.databricks.spark.xml\"\n",
    "                        ).option(\"rowTag\", \"REC\"\n",
    "                                ).option(\"samplingRatio\", 0.001\n",
    "                                        ).load(\"/user/jwlock/WoS/*.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "cites.write.option(\"maxRecordsPerFile\", 10000\n",
    "                  ).parquet(\"wos_core.parquet\", \n",
    "                            mode='overwrite')\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73946716"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cites = sqlC.read.parquet(\"wos_core.parquet\")\n",
    "cites.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
