{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean and prepare Library of Congress book data\n",
    "- Data from the libary of congress: https://www.loc.gov/cds/products/MDSConnect-books_all.html\n",
    "\n",
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "#import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "import pyspark.sql\n",
    "import string\n",
    "sqlC = SQLContext(sc)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert data from xml to parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7e5c3a9ab431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rowTag\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"record\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"samplingRatio\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                                         ).load(\"/user/jwlock/LoC/Books*\")\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loc = sqlC.read.format(\"com.databricks.spark.xml\"\n",
    "                        ).option(\"rowTag\", \"record\"\n",
    "                                ).option(\"samplingRatio\", 0.01\n",
    "                                        ).load(\"/user/jwlock/LoC/Books*\")\n",
    "loc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc.write.option(\"maxRecordsPerFile\", 10000\n",
    "                  ).parquet(\"loc_raw.parquet\", \n",
    "                            mode='overwrite')\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = sqlC.read.parquet('loc_raw.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- controlfield: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _tag: long (nullable = true)\n",
      " |-- datafield: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _ind1: string (nullable = true)\n",
      " |    |    |-- _ind2: string (nullable = true)\n",
      " |    |    |-- _tag: long (nullable = true)\n",
      " |    |    |-- subfield: array (nullable = true)\n",
      " |    |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |    |    |-- _code: string (nullable = true)\n",
      " |-- leader: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loc.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create an ID column for the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = loc.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+---+\n",
      "|        controlfield|           datafield|              leader| id|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "|[[  2010657549,1]...|[[ , ,10,WrappedA...|01627cam a2200397...|  0|\n",
      "|[[  2010657550,1]...|[[ , ,10,WrappedA...|01934cam a2200421...|  1|\n",
      "|[[  2010657551,1]...|[[ , ,10,WrappedA...|01790cam a2200373...|  2|\n",
      "|[[  2010657552,1]...|[[ , ,10,WrappedA...|01564cam a2200361...|  3|\n",
      "|[[  2010657553,1]...|[[ , ,10,WrappedA...|01396cam a2200373...|  4|\n",
      "|[[  2010657554,1]...|[[ , ,10,WrappedA...|01731cam a2200421...|  5|\n",
      "|[[  2010657555,1]...|[[ , ,10,WrappedA...|02519cam a2200517...|  6|\n",
      "|[[  2010657556,1]...|[[ , ,10,WrappedA...|06922cam a2201513...|  7|\n",
      "|[[  2010657557,1]...|[[ , ,10,WrappedA...|01926cam a2200445...|  8|\n",
      "|[[  2010657558,1]...|[[ , ,10,WrappedA...|01255cam a2200349...|  9|\n",
      "|[[  2010657559,1]...|[[ , ,10,WrappedA...|01420cam a2200349...| 10|\n",
      "|[[  2010657560,1]...|[[ , ,10,WrappedA...|02052cam a2200445...| 11|\n",
      "|[[  2010657561,1]...|[[ , ,10,WrappedA...|01753cam a2200445...| 12|\n",
      "|[[  2010657562,1]...|[[ , ,10,WrappedA...|01688cam a2200433...| 13|\n",
      "|[[  2010657563,1]...|[[ , ,10,WrappedA...|01924cam a2200493...| 14|\n",
      "|[[  2010657564,1]...|[[ , ,10,WrappedA...|01995cam a2200481...| 15|\n",
      "|[[  2010657565,1]...|[[ , ,10,WrappedA...|01691cam a2200421...| 16|\n",
      "|[[  2010657566,1]...|[[ , ,10,WrappedA...|01949cam a2200433...| 17|\n",
      "|[[  2010657568,1]...|[[ , ,10,WrappedA...|01372cam a2200409...| 18|\n",
      "|[[  2010657569,1]...|[[ , ,10,WrappedA...|01860cam a2200445...| 19|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from LoC tags\n",
    "- LoC uses different `_tag` values to mean different information about records. This section takes that and saves it to variables with meaninfgul names\n",
    "- The relevant tag documentation is included at the bottom of this notebook and can be found at the data link at the top as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+----+--------------------+\n",
      "| id|_ind1|_ind2|_tag|            subfield|\n",
      "+---+-----+-----+----+--------------------+\n",
      "|  0|     |     |  10|  [[  2010657549,a]]|\n",
      "|  0|     |     |  35|[[(CStRLIN)VAUP90...|\n",
      "|  0|     |     |  40|[[ViU,a], [ViU,c]...|\n",
      "|  0|    0|     |  41|           [[ger,a]]|\n",
      "|  0|    0|    0|  50|[[ML48,a], [[S290...|\n",
      "|  0|     |     |  51|[[Microfilm Music...|\n",
      "|  0|    0|    0| 245|[[Zur Heimkehr :,...|\n",
      "|  0|     |     | 260|[[Berlin :,a], [[...|\n",
      "|  0|     |     | 300|[[[2], 20, [6] p....|\n",
      "|  0|     |     | 500|[[U.S. RISM Libre...|\n",
      "|  0|     |     | 500|[[At head of titl...|\n",
      "|  0|     |     | 500|[[Singers' names ...|\n",
      "|  0|     |    0| 650|[[Dramatic music,...|\n",
      "|  0|     |     | 653| [[Gerechtigkeit,a]]|\n",
      "|  0|     |     | 653|        [[Friede,a]]|\n",
      "|  0|     |     | 653|        [[Morgen,a]]|\n",
      "|  0|     |     | 653|        [[Mittag,a]]|\n",
      "|  0|     |     | 653|         [[Abend,a]]|\n",
      "|  0|     |     | 653|  [[Jahreszeiten,a]]|\n",
      "|  0|     |     | 653|       [[KuÌˆnste,a]]|\n",
      "+---+-----+-----+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = loc.select('id', explode('datafield').alias('d')).select('id', 'd.*')#.show()\n",
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=0, title=u'Zur Heimkehr :'),\n",
       " Row(id=1, title=u'Ein Soldat :'),\n",
       " Row(id=2, title=u'Eine neue Station, oder, Der Herr Eisenbahn-Director :'),\n",
       " Row(id=3, title=u'Sein Schatten :'),\n",
       " Row(id=4, title=u'Judith :'),\n",
       " Row(id=5, title=u'Un curioso accidente :'),\n",
       " Row(id=6, title=u'Gian Maria Visconti, duca di Milano :'),\n",
       " Row(id=7, title=u'Ai\\u0308da :'),\n",
       " Row(id=8, title=u\"Cuore di madre, ossia, La contessa d'Altenberg :\"),\n",
       " Row(id=9, title=u'Giuditta :'),\n",
       " Row(id=10, title=u'Ezechia :'),\n",
       " Row(id=11, title=u'Una burla :'),\n",
       " Row(id=12, title=u'Il conte di Monreal :'),\n",
       " Row(id=13, title=u\"L'avvocato Patelin :\"),\n",
       " Row(id=14, title=u\"Il trionfo d'amore :\"),\n",
       " Row(id=15, title=u'Il califfo :'),\n",
       " Row(id=16, title=u\"Linda d'Ispahan :\"),\n",
       " Row(id=17, title=u'Le astuzie femminili :'),\n",
       " Row(id=18, title=u'Il figliuol prodigo :'),\n",
       " Row(id=19, title=u'I due mariti :')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 245\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "title = t2.filter(col('_code') == 'a').select('id', col('_value').alias('title'))\n",
    "subtitle = t2.filter(col('_code') == 'b').select('id', col('_value').alias('subtitle'))\n",
    "\n",
    "title.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "|  id|             summary|\n",
      "+----+--------------------+\n",
      "|9585|Typescript includ...|\n",
      "|9610|National Symphony...|\n",
      "|9611|National Symphony...|\n",
      "|9612|National Symphony...|\n",
      "|9613|National Symphony...|\n",
      "|9614|National Symphony...|\n",
      "|9615|National Symphony...|\n",
      "|9616|National Symphony...|\n",
      "|9617|National Symphony...|\n",
      "|9618|National Symphony...|\n",
      "|9619|National Symphony...|\n",
      "|9620|National Symphony...|\n",
      "|9621|National Symphony...|\n",
      "|9622|National Symphony...|\n",
      "|9623|National Symphony...|\n",
      "|9624|National Symphony...|\n",
      "|9625|National Symphony...|\n",
      "|9626|National Symphony...|\n",
      "|9627|National Symphony...|\n",
      "|9628|National Symphony...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 520\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "summary = t2.filter(col('_code') == 'a').select('id', \n",
    "                                                col('_value').alias('summary'))\n",
    "summary_expanded = t2.filter(col('_code') == 'b'\n",
    "                            ).select('id', \n",
    "                                     col('_value').alias('summary_expanded'))\n",
    "\n",
    "summary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=218, contents=u'Vorbemerkung, p. 3-4 -- Wolfgang Amadeus Mozart als Freimaurer, p. 5-10 -- Die Zauberflo\\u0308te (essay), p. 11-29 -- Die Zauberflo\\u0308te (libretto), p. 31-64.'),\n",
       " Row(id=1259, contents=u'I. Der Freischu\\u0308tz. Volks-Oper, p. 1-62 -- II. scho\\u0308pfungsgeschichte des Freischu\\u0308tzen. Biographische Novelle, p. 63-138 -- III. Briefe, p. 139-176 -- IV. Gedichte, p. 177-210 -- V. Erla\\u0308uterungen. (Aus Sprache und Geschichte), p. 211-242 -- VI. Miscellen, p. 243-272.'),\n",
       " Row(id=3160, contents=u'Dem Unendlichen p. 1-4 -- Vertrauen auf Gott, p. 5-11.'),\n",
       " Row(id=3963, contents=u'Erstes Bild. Die Arretirung -- Zweites Bild. Die tropische Taufe -- Drittes Bild. Die Favorit-Sultanin -- Viertes Bild. Der Kaiser von Japan.'),\n",
       " Row(id=5655, contents=u'1. Le sventure fortunate, p. 1-32 -- 2. La finta zingara, p. 33-71.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 505\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "contents = t2.filter(col('_code') == 'a').select('id', \n",
    "                                                col('_value').alias('contents'))\n",
    "\n",
    "contents.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|pubdate|\n",
      "+---+-------+\n",
      "|  0|  1871.|\n",
      "|  1|  1871.|\n",
      "|  2|  1871.|\n",
      "|  3|  1871.|\n",
      "|  4|  1871.|\n",
      "|  5|[1871?]|\n",
      "|  6|  1871.|\n",
      "|  7|  1871.|\n",
      "|  8|  1871.|\n",
      "|  9| [1871]|\n",
      "| 10|  1871.|\n",
      "| 11|  1871.|\n",
      "| 12|[1871?]|\n",
      "| 13|  1871.|\n",
      "| 14|  1871.|\n",
      "| 15|  1871.|\n",
      "| 16|  1871.|\n",
      "| 17|  1871.|\n",
      "| 18|  1871.|\n",
      "| 19|[1871?]|\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 260\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "pubdate = t2.filter(col('_code') == 'c').select('id', \n",
    "                                                col('_value').alias('pubdate'))\n",
    "\n",
    "pubdate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|         main_author|\n",
      "+---+--------------------+\n",
      "|  1|       Bial, Rudolf,|\n",
      "|  2|       Bial, Rudolf,|\n",
      "|  3|Flotow, Friedrich...|\n",
      "|  4|     Doppler, Franz,|\n",
      "|  5| Ricci-Stolz, Luigi,|\n",
      "|  6|      Vicini, Luigi,|\n",
      "|  7|    Verdi, Giuseppe,|\n",
      "|  8|Rossi, Giovanni G...|\n",
      "|  9|   Righi, Telesforo,|\n",
      "| 10|    Picchi, Ermanno,|\n",
      "| 11| Parisini, Federico,|\n",
      "| 12|Gandolfi, Riccard...|\n",
      "| 13|  Montuoro, Achille.|\n",
      "| 14| Matteini, Raffaele.|\n",
      "| 15|  De Champs, Ettore,|\n",
      "| 16|Malipiero, France...|\n",
      "| 17| Cimarosa, Domenico,|\n",
      "| 18|     Auber, D. F. E.|\n",
      "| 19|  D'Arienzo, Nicola,|\n",
      "| 20|    Angeloni, Carlo,|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 100\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "main_author = t2.filter(col('_code') == 'a').select('id', \n",
    "                                                col('_value').alias('main_author'))\n",
    "\n",
    "main_author.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=9945, other_author=[u'Hart, Jillian.', u'Davidson, Carolyn,', u'Bridges, Kate,']),\n",
       " Row(id=10422, other_author=[u'Seitanidi, Maria May.', u'Crane, Andrew,']),\n",
       " Row(id=11190, other_author=[u'Kiwan, Dina,']),\n",
       " Row(id=11434, other_author=[u'Hinrichs-Rahlwes, Rainer.']),\n",
       " Row(id=11745, other_author=[u'Thompson, Andrew R.', u'Jenkinson, Elizabeth', u'Rumsey, Nichola.', u'Newell, Robert,']),\n",
       " Row(id=11945, other_author=[u'Eldridge, Elleanor,', u'Moody, Joycelyn,']),\n",
       " Row(id=12044, other_author=[u'Dunn, Jim.', u'Strong, Ron.']),\n",
       " Row(id=13098, other_author=[u'Miyazaki, Hayao,', u'Hubbert, Jim,']),\n",
       " Row(id=13638, other_author=[u'Smith, Robin James,', u'Hetherington, Kevin,']),\n",
       " Row(id=14846, other_author=[u'Stepan, Alfred C.']),\n",
       " Row(id=15057, other_author=[u'Malenczyk, Rita,']),\n",
       " Row(id=15322, other_author=[u'Bruce, Bertram C.,', u'Bishop, Ann P.,', u'Budhathoki, Nama R.,']),\n",
       " Row(id=15371, other_author=[u'Cohn, Stephen M.,', u'Dolich, Matthew,']),\n",
       " Row(id=17048, other_author=[u'Wiesner, Claudia.', u'Schmidt-Gleim, Meike.']),\n",
       " Row(id=18147, other_author=[u'Gellner, David N.', u'Schendel, Willem van.']),\n",
       " Row(id=19141, other_author=[u'Leonhard, Herb,']),\n",
       " Row(id=19163, other_author=[u'Lane, Erin,', u'Okoro, Enuma,']),\n",
       " Row(id=19771, other_author=[u'Johns, Geoff,', u'Pasarin, Fernando,']),\n",
       " Row(id=19907, other_author=[u'Gall, Gregor.', u'Dundon, Tony,']),\n",
       " Row(id=21209, other_author=[u'Gill, Stephen.', u'Cutler, A. Claire.'])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 700\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "other_author = t2.filter(col('_code') == 'a').select('id', \n",
    "                                                col('_value').alias('other_author'))\n",
    "\n",
    "other_author = other_author.groupby('id').agg(collect_list('other_author').alias('other_author'))\n",
    "\n",
    "other_author.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Select ISBN and ISSN data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=9758, isbn=u'1420104578'),\n",
       " Row(id=9843, isbn=u'9780756404932'),\n",
       " Row(id=9867, isbn=u'9780373655267'),\n",
       " Row(id=9978, isbn=u'9780373618279'),\n",
       " Row(id=9994, isbn=u'9780373694587'),\n",
       " Row(id=10055, isbn=u'9781624910128'),\n",
       " Row(id=10105, isbn=u'0071790233'),\n",
       " Row(id=10455, isbn=u'9780819816382'),\n",
       " Row(id=10484, isbn=u'9781611861167'),\n",
       " Row(id=10537, isbn=u'9781617039003'),\n",
       " Row(id=10635, isbn=u'9780345539786'),\n",
       " Row(id=10655, isbn=u'9780415837088'),\n",
       " Row(id=10694, isbn=u'9780802410795'),\n",
       " Row(id=10726, isbn=u'9780891123927'),\n",
       " Row(id=10744, isbn=u'9781284026900'),\n",
       " Row(id=10824, isbn=u'9780345535825'),\n",
       " Row(id=10868, isbn=u'9781466643338'),\n",
       " Row(id=10903, isbn=u'9780749469665'),\n",
       " Row(id=11004, isbn=u'9781618510495'),\n",
       " Row(id=11053, isbn=u'1421412381'),\n",
       " Row(id=11185, isbn=u'9780230361805'),\n",
       " Row(id=11273, isbn=u'9780062211316'),\n",
       " Row(id=11519, isbn=u'9781477762394'),\n",
       " Row(id=11590, isbn=u'9780544120044'),\n",
       " Row(id=11595, isbn=u'9781555717315'),\n",
       " Row(id=11604, isbn=u'9781137007155'),\n",
       " Row(id=11731, isbn=u'9781118250440'),\n",
       " Row(id=11779, isbn=u'9781477727959'),\n",
       " Row(id=11839, isbn=u'9783110315097'),\n",
       " Row(id=12084, isbn=u'9781842178003')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 20\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "isbn = t2.filter(col('_code') == 'a').select('id', \n",
    "                                                col('_value').alias('isbn'))\n",
    "\n",
    "#isbn = isbn.groupby('id').agg(concat_ws(', ', collect_list('isbn')).alias('ISBNs'))\n",
    "#isbn = isbn.withColumn('isbn', regexp_replace('isbn', '\\D', ''))\n",
    "#isbn = isbn.withColumn('isbn', regexp_replace('isbn', '-', ''))\n",
    "isbn = isbn.withColumn('isbn', regexp_replace('isbn', ':', ''))\n",
    "isbn = isbn.withColumn('isbn', regexp_replace('isbn', '\\(.+\\)', ''))\n",
    "isbn = isbn.withColumn('isbn', regexp_replace('isbn', ' ', ''))\n",
    "\n",
    "isbn.sample(False, 0.01).take(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+\n",
      "|          id|         issn|\n",
      "+------------+-------------+\n",
      "|  8589941913|    1059-1133|\n",
      "| 34359748114|    2211-8101|\n",
      "| 42949695364|    2192-855X|\n",
      "| 51539640426|    0081-6914|\n",
      "| 68719497479|   1449701130|\n",
      "| 68719498105|9783790825930|\n",
      "| 77309422617|    1559-5374|\n",
      "| 85899370405|    1934-8525|\n",
      "| 94489281980|    0169-9156|\n",
      "| 94489283415|    0769-2633|\n",
      "| 94489303015|     15709310|\n",
      "| 94489309950|    1815-3712|\n",
      "|103079215920|    0554-8128|\n",
      "|103079215997|    0554-8128|\n",
      "|103079223063|    1396-1810|\n",
      "|103079245183|    0392-4866|\n",
      "|103079249425|    1310-8247|\n",
      "|103079249648|    1313-8138|\n",
      "|111669184984|     16192435|\n",
      "|120259086556|     18362060|\n",
      "+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 22\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "issn = t2.filter(col('_code') == 'a').select('id', \n",
    "                                                col('_value').alias('issn'))\n",
    "\n",
    "issn = issn.withColumn('issn', regexp_replace('issn', ':', ''))\n",
    "issn = issn.withColumn('issn', regexp_replace('issn', '\\(.+\\)', ''))\n",
    "issn = issn.withColumn('issn', regexp_replace('issn', ' ', ''))\n",
    "\n",
    "issn.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|       subject|\n",
      "+---+--------------+\n",
      "|  0|Dramatic music|\n",
      "|  1|        Operas|\n",
      "|  2|Dramatic music|\n",
      "|  3|        Operas|\n",
      "|  4|        Operas|\n",
      "|  5|        Operas|\n",
      "|  6|        Operas|\n",
      "|  7|        Operas|\n",
      "|  8|        Operas|\n",
      "|  9|        Operas|\n",
      "| 10|     Oratorios|\n",
      "| 11|        Operas|\n",
      "| 12|        Operas|\n",
      "| 13|        Operas|\n",
      "| 14|        Operas|\n",
      "| 15|        Operas|\n",
      "| 16|        Operas|\n",
      "| 17|        Operas|\n",
      "| 18|        Operas|\n",
      "| 19|        Operas|\n",
      "+---+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t2 = tmp.filter(col('_tag') == 650\n",
    "                  ).select('id', explode('subfield').alias('s')\n",
    "                          ).select('id', 's.*')\n",
    "\n",
    "subjects = t2.filter(col('_code') == 'a').select('id', \n",
    "                                                col('_value').alias('subject'))\n",
    "\n",
    "#isbn = isbn.groupby('id').agg(concat_ws(', ', collect_list('isbn')).alias('ISBNs'))\n",
    "\n",
    "subjects.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all results together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- subtitle: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- issn: string (nullable = true)\n",
      " |-- pubdate: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- summary_expanded: string (nullable = true)\n",
      " |-- subject: string (nullable = true)\n",
      " |-- contents: string (nullable = true)\n",
      " |-- main_author: string (nullable = true)\n",
      " |-- other_author: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "together = title.join(subtitle, on='id', how='outer')\n",
    "together = together.join(isbn, on='id', how='outer')\n",
    "together = together.join(issn, on='id', how='outer')\n",
    "together = together.join(pubdate, on='id', how='outer')\n",
    "together = together.join(summary, on='id', how='outer')\n",
    "together = together.join(summary_expanded, on='id', how='outer')\n",
    "together = together.join(subjects, on='id', how='outer')\n",
    "together = together.join(contents, on='id', how='outer')\n",
    "together = together.join(main_author, on='id', how='outer')\n",
    "together = together.join(other_author, on='id', how='outer')\n",
    "\n",
    "together.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaces = \"\"\n",
    "for i in string.punctuation:\n",
    "    spaces += \" \"\n",
    "    \n",
    "together = together.withColumn('loc_bare_text', \n",
    "                         translate(lower(concat_ws(\" \", \n",
    "                                                   together.title, \n",
    "                                                   together.subtitle, \n",
    "                                                   together.contents,\n",
    "                                                   together.summary,\n",
    "                                                   together.summary_expanded, \n",
    "                                                   together.subject,\n",
    "                                                  )),\n",
    "                                   string.punctuation, \n",
    "                                   spaces\n",
    "                                  ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean up text data \n",
    "- For ease of matching, we remove characters that are inconsistently used such as colons and periods in book titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['title', 'subtitle', 'main_author', 'pubdate']\n",
    "\n",
    "remove = '.:/'\n",
    "\n",
    "for c in cols:\n",
    "    together = together.withColumn(c, translate(c, remove, spaces))\n",
    "    together = together.withColumn(c, regexp_replace(col(c), ',$', ''))\n",
    "    together = together.withColumn(c, lower(trim(col(c))))\n",
    "    \n",
    "#together.sample(False, 0.01).select('title', 'subtitle', 'main_author', 'pubdate').take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, title: string, subtitle: string, isbn: string, issn: string, pubdate: string, summary: string, summary_expanded: string, subject: string, contents: string, main_author: string, other_author: array<string>, loc_bare_text: string]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#together.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more sophisticated duplicate dropping, because some data are inconsistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "together = together.dropDuplicates(subset=['isbn', 'id', 'issn'])\n",
    "together = together.dropDuplicates(subset=['isbn', 'main_author'])\n",
    "together = together.dropDuplicates(subset=['isbn', 'title'])\n",
    "#together.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(isbn=None, count=1444620),\n",
       " Row(isbn=u'8570602332', count=66),\n",
       " Row(isbn=u'0815199031', count=62),\n",
       " Row(isbn=u'9789989550256', count=59),\n",
       " Row(isbn=u'9989550255', count=54),\n",
       " Row(isbn=u'7222038752', count=51),\n",
       " Row(isbn=u'0534274943', count=48),\n",
       " Row(isbn=u'7543451301', count=47),\n",
       " Row(isbn=u'9025606385', count=45),\n",
       " Row(isbn=u'9787811185133', count=44),\n",
       " Row(isbn=u'781118513X', count=43),\n",
       " Row(isbn=u'0815199155', count=42),\n",
       " Row(isbn=u'2252016906', count=42),\n",
       " Row(isbn=u'7805233578', count=39),\n",
       " Row(isbn=u'8930080014', count=38),\n",
       " Row(isbn=u'081519918X', count=36),\n",
       " Row(isbn=u'0415203929', count=35),\n",
       " Row(isbn=u'8970131450', count=34),\n",
       " Row(isbn=u'7805233586', count=32),\n",
       " Row(isbn=u'8476790228', count=32)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.groupby('isbn').count().sort(desc('count')).take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(issn=None, count=8359301),\n",
       " Row(issn=u'1062-4007', count=112),\n",
       " Row(issn=u'1099-7326', count=37),\n",
       " Row(issn=u'1443-4911', count=10),\n",
       " Row(issn=u'1530-1028', count=9),\n",
       " Row(issn=u'0187-425X', count=8),\n",
       " Row(issn=u'1531-1627', count=7),\n",
       " Row(issn=u'9788886509855', count=6),\n",
       " Row(issn=u'9788822230980', count=6),\n",
       " Row(issn=u'0272-9172', count=5),\n",
       " Row(issn=u'9788831194358', count=5),\n",
       " Row(issn=u'1326-6004', count=5),\n",
       " Row(issn=u'2211-3061', count=4),\n",
       " Row(issn=u'1087-4852', count=4),\n",
       " Row(issn=u'2211-8101', count=4),\n",
       " Row(issn=u'2213-5421', count=4),\n",
       " Row(issn=u'1396-1810', count=4),\n",
       " Row(issn=u'1874-0294', count=4),\n",
       " Row(issn=u'1059-1133', count=4),\n",
       " Row(issn=u'0340-1022', count=4)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "together.groupby('issn').count().sort(desc('count')).take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "together.write.option(\"maxRecordsPerFile\", 10000\n",
    "                  ).parquet(\"loc_books.parquet\", \n",
    "                            mode='overwrite')\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoC tag documentation below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "245 a is title\n",
    "245 b is subtitle\n",
    "\n",
    "650 are subjects\n",
    "300 is physical description\n",
    "050 LoC call number\n",
    "260 publisher / edition info\n",
    "040 catalogue source\n",
    "020 ISBNs\n",
    "022 ISSNs\n",
    "043 geography\n",
    "035 sys control num\n",
    "042 auth code\n",
    "082 dewey decimal\n",
    "500 general note\n",
    "504 bibliographic note\n",
    "\n",
    "260 - PUBLICATION, DISTRIBUTION, ETC. (IMPRINT) (R)\n",
    "   Indicators\n",
    "      First - Sequence of publishing statements\n",
    "         # - Not applicable/No information provided/Earliest available publisher\n",
    "         2 - Intervening publisher\n",
    "         3 - Current/latest publisher\n",
    "      Second - Undefined\n",
    "         # - Undefined\n",
    "      First - Presence of publisher in imprint (BK MP MU SE) [OBSOLETE]\n",
    "         0 - Publisher, distributor, etc. is present\n",
    "         1 - Publisher, distributor, etc. is not present\n",
    "      Second - Added entry/publisher relationship (SE) [OBSOLETE]\n",
    "         0 - Publisher, distributor, etc. not same as issuing body in added entry\n",
    "         1 - Publisher, distributor, etc. same as issuing body in added entry\n",
    "   Subfield Codes\n",
    "      $a - Place of publication, distribution, etc. (R)\n",
    "      $b - Name of publisher, distributor, etc. (R)\n",
    "      $c - Date of publication, distribution, etc. (R)\n",
    "      $d - Plate or publisher's number for music (Pre-AACR 2) (NR) [LOCAL]\n",
    "      $e - Place of manufacture (R)\n",
    "      $f - Manufacturer (R)\n",
    "      $g - Date of manufacture (R)\n",
    "      $3 - Materials specified (NR)\n",
    "      $6 - Linkage (NR)\n",
    "      $8 - Field link and sequence number (R)\n",
    "\n",
    "520 - SUMMARY, ETC. (R)\n",
    "   Indicators\n",
    "      First - Display constant controller\n",
    "         # - Summary\n",
    "         0 - Subject\n",
    "         1 - Review\n",
    "         2 - Scope and content\n",
    "         3 - Abstract\n",
    "         4 - Content advice\n",
    "         8 - No display constant generated\n",
    "      Second - Undefined\n",
    "         # - Undefined\n",
    "   Subfield Codes\n",
    "      $a - Summary, etc. note (NR)\n",
    "      $b - Expansion of summary note (NR)\n",
    "      $c - Assigning agency (NR)\n",
    "      $u - Uniform Resource Identifier (R)\n",
    "      $z - Source of note information (NR) [OBSOLETE]\n",
    "      $2 - Source (NR)\n",
    "      $3 - Materials specified (NR)\n",
    "      $6 - Linkage (NR)\n",
    "      $8 - Field link and sequence number (R)\n",
    "      \n",
    "505 - FORMATTED CONTENTS NOTE (R)\n",
    "   Indicators\n",
    "      First - Display constant controller\n",
    "         0 - Contents\n",
    "         1 - Incomplete contents\n",
    "         2 - Partial contents\n",
    "         8 - No display constant generated\n",
    "      Second - Level of content designation\n",
    "         # - Basic\n",
    "         0 - Enhanced\n",
    "   Subfield Codes\n",
    "      $a - Formatted contents note (NR)\n",
    "      $g - Miscellaneous information (R)\n",
    "      $r - Statement of responsibility (R)\n",
    "      $t - Title (R)\n",
    "      $u - Uniform Resource Identifier (R) \n",
    "      $6 - Linkage (NR)\n",
    "      $8 - Field link and sequence number (R)\n",
    "\n",
    "100 - MAIN ENTRY--PERSONAL NAME (NR)\n",
    "   Indicators\n",
    "      First - Type of personal name entry element\n",
    "         0 - Forename\n",
    "         1 - Surname\n",
    "         2 - Multiple surname [OBSOLETE]\n",
    "         3 - Family name\n",
    "      Second - Undefined\n",
    "         # - Undefined\n",
    "      Second - Main entry/subject relationship (BK MU SE) [OBSOLETE]\n",
    "   Subfield Codes\n",
    "      $a - Personal name (NR)\n",
    "      $b - Numeration (NR)\n",
    "      $c - Titles and other words associated with a name (R)\n",
    "      $d - Dates associated with a name (NR)\n",
    "      $e - Relator term (R)\n",
    "      $f - Date of a work (NR)\n",
    "      $g - Miscellaneous information (R)\n",
    "      $j - Attribution qualifier (R)\n",
    "      $k - Form subheading (R)\n",
    "      $l - Language of a work (NR)\n",
    "      $n - Number of part/section of a work (R)\n",
    "      $p - Name of part/section of a work (R)\n",
    "      $q - Fuller form of name (NR)\n",
    "      $t - Title of a work (NR)\n",
    "      $u - Affiliation (NR)\n",
    "      $0 - Authority record control number or standard number (R)\n",
    "      $1 - Real World Object URI (R)\n",
    "      $4 - Relationship (R)\n",
    "      $6 - Linkage (NR)\n",
    "      $8 - Field link and sequence number (R)\n",
    "      \n",
    "700 - ADDED ENTRY--PERSONAL NAME (R)\n",
    "   Indicators\n",
    "      First - Type of personal name entry element\n",
    "         0 - Forename\n",
    "         1 - Surname\n",
    "         2 - Multiple surname [OBSOLETE]\n",
    "         3 - Family name\n",
    "      Second - Type of added entry\n",
    "         # - No information provided\n",
    "         0 - Alternative entry (BK CF MP MU SE MX) [OBSOLETE]\n",
    "         1 - Secondary entry (BK CF MP MU SE MX) [OBSOLETE]\n",
    "         1 - Printed on card (VM) [OBSOLETE]\n",
    "         2 - Analytical entry\n",
    "         3 - Not printed on card (VM) [OBSOLETE]\n",
    "   Subfield Codes\n",
    "      $a - Personal name (NR)\n",
    "      $b - Numeration (NR)\n",
    "      $c - Titles and other words associated with a name (R)\n",
    "      $d - Dates associated with a name (NR)\n",
    "      $e - Relator term (R)\n",
    "      $f - Date of a work (NR)\n",
    "      $g - Miscellaneous information (R)\n",
    "      $h - Medium (NR)\n",
    "      $i - Relationship information (R)\n",
    "      $j - Attribution qualifier (R) \n",
    "      $k - Form subheading (R)\n",
    "      $l - Language of a work (NR)\n",
    "      $m - Medium of performance for music (R)\n",
    "      $n - Number of part/section of a work (R)\n",
    "      $o - Arranged statement for music (NR)\n",
    "      $p - Name of part/section of a work (R)\n",
    "      $q - Fuller form of name (NR)\n",
    "      $r - Key for music (NR)\n",
    "      $s - Version (R)\n",
    "      $t - Title of a work (NR)\n",
    "      $u - Affiliation (NR)\n",
    "      $x - International Standard Serial Number (NR)\n",
    "      $0 - Authority record control number or standard number (R)\n",
    "      $1 - Real World Object URI (R)\n",
    "      $3 - Materials specified (NR)\n",
    "      $4 - Relationship (R)\n",
    "      $5 - Institution to which field applies (NR)\n",
    "      $6 - Linkage (NR)\n",
    "      $8 - Field link and sequence number (R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
